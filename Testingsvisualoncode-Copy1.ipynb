{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c9f0b7e-f1ee-440f-9c14-49df371d41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e02b22f-7515-4dc6-8f6b-77adaabb38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"../Assignment 2_diabetes_classification/diabetes_binary_classification_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00555c26-26c4-49fc-aa4a-575f39164785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Checks whats in the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9da9b80b-4b63-4866-87c2-3cb9eb48d2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24206"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks duplicated in dataset\n",
    "# There is 24206 duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "105537c0-3fa0-4ba4-95aa-fe1b5683403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the duplicates\n",
    "#data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a2c7baa-a227-403c-8b8a-c995082e93bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 177576\n",
      "Validation set size: 38052\n",
      "Test set size: 38052\n",
      "Logistic Regression Validation Accuracy: 0.8637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     32747\n",
      "         1.0       0.54      0.15      0.24      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.71      0.57      0.58     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n",
      "Decision Tree Validation Accuracy: 0.8628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.92     32747\n",
      "         1.0       0.53      0.15      0.24      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.70      0.57      0.58     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n",
      "Random Forest Validation Accuracy: 0.8645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93     32747\n",
      "         1.0       0.60      0.09      0.15      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.73      0.54      0.54     38052\n",
      "weighted avg       0.83      0.86      0.82     38052\n",
      "\n",
      "Voting Classifier Validation Accuracy: 0.8660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93     32747\n",
      "         1.0       0.60      0.12      0.20      5305\n",
      "\n",
      "    accuracy                           0.87     38052\n",
      "   macro avg       0.74      0.55      0.56     38052\n",
      "weighted avg       0.84      0.87      0.83     38052\n",
      "\n",
      "Logistic Regression Test Accuracy: 0.8686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     32858\n",
      "         1.0       0.57      0.15      0.24      5194\n",
      "\n",
      "    accuracy                           0.87     38052\n",
      "   macro avg       0.72      0.57      0.59     38052\n",
      "weighted avg       0.84      0.87      0.83     38052\n",
      "\n",
      "Decision Tree Test Accuracy: 0.8645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     32858\n",
      "         1.0       0.51      0.15      0.24      5194\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.70      0.57      0.58     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n",
      "Random Forest Test Accuracy: 0.8680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93     32858\n",
      "         1.0       0.62      0.09      0.15      5194\n",
      "\n",
      "    accuracy                           0.87     38052\n",
      "   macro avg       0.74      0.54      0.54     38052\n",
      "weighted avg       0.84      0.87      0.82     38052\n",
      "\n",
      "Voting Classifier Test Accuracy: 0.8692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93     32858\n",
      "         1.0       0.61      0.12      0.20      5194\n",
      "\n",
      "    accuracy                           0.87     38052\n",
      "   macro avg       0.74      0.55      0.56     38052\n",
      "weighted avg       0.84      0.87      0.83     38052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop('Diabetes_binary', axis=1)\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% train\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% validation, 15% test\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "# Create preprocessing pipelines for numeric and categorical features\n",
    "numeric_features = ['BMI', 'MentHlth', 'PhysHlth', 'Age', 'Income']  # Non-binary variables\n",
    "categorical_features = ['GenHlth', 'Education', 'HighBP', 'HighChol', \n",
    "                        'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', \n",
    "                        'PhysActivity', 'Fruits', 'Veggies', \n",
    "                        'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', \n",
    "                        'DiffWalk', 'Sex']  # Binary variables\n",
    "\n",
    "# Create preprocessing for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess training data (numerical and categorical features)\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Preprocess validation and test data\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "decision_tree = DecisionTreeClassifier(max_depth=10)\n",
    "random_forest = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg),\n",
    "    ('decision_tree', decision_tree),\n",
    "    ('random_forest', random_forest)],\n",
    "    voting='hard')  # 'hard' for majority voting\n",
    "\n",
    "# Fit models on the processed training data\n",
    "log_reg.fit(X_train_processed, y_train)\n",
    "decision_tree.fit(X_train_processed, y_train)\n",
    "random_forest.fit(X_train_processed, y_train)\n",
    "voting_clf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "log_reg_val_pred = log_reg.predict(X_val_processed)\n",
    "decision_tree_val_pred = decision_tree.predict(X_val_processed)\n",
    "random_forest_val_pred = random_forest.predict(X_val_processed)\n",
    "voting_val_pred = voting_clf.predict(X_val_processed)\n",
    "\n",
    "# Evaluate models on validation data and print results\n",
    "for model_name, predictions in zip(\n",
    "    [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Voting Classifier\"],\n",
    "    [log_reg_val_pred, decision_tree_val_pred, random_forest_val_pred, voting_val_pred]\n",
    "):\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    print(f\"{model_name} Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_val, predictions))\n",
    "\n",
    "# Make predictions on the test set\n",
    "log_reg_test_pred = log_reg.predict(X_test_processed)\n",
    "decision_tree_test_pred = decision_tree.predict(X_test_processed)\n",
    "random_forest_test_pred = random_forest.predict(X_test_processed)\n",
    "voting_test_pred = voting_clf.predict(X_test_processed)\n",
    "\n",
    "# Evaluate models on test data and print results\n",
    "for model_name, predictions in zip(\n",
    "    [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Voting Classifier\"],\n",
    "    [log_reg_test_pred, decision_tree_test_pred, random_forest_test_pred, voting_test_pred]\n",
    "):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "11fe236a-9a13-4d0b-88d8-6d4ff1dda136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 177576\n",
      "Validation set size: 38052\n",
      "Test set size: 38052\n",
      "Top correlations with Diabetes_binary:\n",
      "Diabetes_binary             1.000000\n",
      "HighBP_1.0                  0.263531\n",
      "DiffWalk_1.0                0.221507\n",
      "BMI                         0.218647\n",
      "HighChol_1.0                0.197866\n",
      "GenHlth_4.0                 0.186045\n",
      "HeartDiseaseorAttack_1.0    0.179718\n",
      "Age                         0.176577\n",
      "PhysHlth                    0.171694\n",
      "GenHlth_5.0                 0.156761\n",
      "PhysActivity_0.0            0.118985\n",
      "Stroke_1.0                  0.107874\n",
      "GenHlth_3.0                 0.071468\n",
      "MentHlth                    0.070958\n",
      "CholCheck_1.0               0.065421\n",
      "Education_4.0               0.062446\n",
      "Smoker_1.0                  0.062066\n",
      "Education_3.0               0.058617\n",
      "Education_2.0               0.058124\n",
      "Veggies_0.0                 0.057552\n",
      "HvyAlcoholConsump_0.0       0.057065\n",
      "Fruits_0.0                  0.039896\n",
      "NoDocbcCost_1.0             0.033110\n",
      "Sex_1.0                     0.032150\n",
      "Education_5.0               0.014771\n",
      "AnyHealthcare_1.0           0.014540\n",
      "Education_1.0               0.010815\n",
      "AnyHealthcare_0.0          -0.014540\n",
      "Sex_0.0                    -0.032150\n",
      "NoDocbcCost_0.0            -0.033110\n",
      "Fruits_1.0                 -0.039896\n",
      "HvyAlcoholConsump_1.0      -0.057065\n",
      "Veggies_1.0                -0.057552\n",
      "Smoker_0.0                 -0.062066\n",
      "CholCheck_0.0              -0.065421\n",
      "Education_6.0              -0.105820\n",
      "Stroke_0.0                 -0.107874\n",
      "PhysActivity_1.0           -0.118985\n",
      "GenHlth_2.0                -0.143656\n",
      "GenHlth_1.0                -0.154189\n",
      "Income                     -0.164444\n",
      "HeartDiseaseorAttack_0.0   -0.179718\n",
      "HighChol_0.0               -0.197866\n",
      "DiffWalk_0.0               -0.221507\n",
      "HighBP_0.0                 -0.263531\n",
      "Name: Diabetes_binary, dtype: float64\n",
      "Logistic Regression Validation Accuracy: 0.8637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     32747\n",
      "         1.0       0.54      0.15      0.24      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.71      0.57      0.58     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n",
      "Decision Tree Validation Accuracy: 0.8630\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.92     32747\n",
      "         1.0       0.53      0.15      0.24      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.70      0.57      0.58     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n",
      "Random Forest Validation Accuracy: 0.8646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93     32747\n",
      "         1.0       0.60      0.09      0.15      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.73      0.54      0.54     38052\n",
      "weighted avg       0.83      0.86      0.82     38052\n",
      "\n",
      "Voting Classifier Validation Accuracy: 0.8663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93     32747\n",
      "         1.0       0.61      0.12      0.20      5305\n",
      "\n",
      "    accuracy                           0.87     38052\n",
      "   macro avg       0.74      0.55      0.56     38052\n",
      "weighted avg       0.84      0.87      0.83     38052\n",
      "\n",
      "Logistic Regression Test Accuracy: 0.8686\n",
      "Decision Tree Test Accuracy: 0.8644\n",
      "Random Forest Test Accuracy: 0.8682\n",
      "Voting Classifier Test Accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example dataset loading (replace with actual data file)\n",
    "# data = pd.read_csv('../Assignment2_diabetes_classification/diabetes_binary_classification_data.csv')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop('Diabetes_binary', axis=1)\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% train\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% validation, 15% test\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "# Create preprocessing pipelines for numeric and categorical features\n",
    "numeric_features = ['BMI', 'MentHlth', 'PhysHlth','Age','Income']  # Non-binary variables\n",
    "categorical_features = ['GenHlth', 'Education', 'HighBP', 'HighChol', 'CholCheck', \n",
    "                        'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', \n",
    "                        'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', \n",
    "                        'NoDocbcCost', 'DiffWalk', 'Sex']  # Binary variables\n",
    "\n",
    "# Create preprocessing for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Preprocess training data (numerical and categorical features)\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Retrieve the column names from preprocessor (numeric + one-hot encoded features)\n",
    "processed_columns = numeric_features + list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
    "\n",
    "# Convert the processed NumPy array back into a DataFrame with column names\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed, columns=processed_columns)\n",
    "\n",
    "# Add the target variable to the DataFrame\n",
    "X_train_processed_df['Diabetes_binary'] = y_train.reset_index(drop=True)\n",
    "\n",
    "# Perform correlation analysis\n",
    "correlation_matrix = X_train_processed_df.corr()\n",
    "sorted_correlations = correlation_matrix['Diabetes_binary'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Top correlations with Diabetes_binary:\")\n",
    "print(sorted_correlations)\n",
    "\n",
    "# Define models\n",
    "log_reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "decision_tree = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', DecisionTreeClassifier(max_depth=10))])\n",
    "\n",
    "random_forest = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', RandomForestClassifier(n_estimators=50, max_depth=10))])\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg),\n",
    "    ('decision_tree', decision_tree),\n",
    "    ('random_forest', random_forest)],\n",
    "    voting='hard')  # 'hard' for majority voting\n",
    "\n",
    "# Fit models on the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "log_reg_val_pred = log_reg.predict(X_val)\n",
    "decision_tree_val_pred = decision_tree.predict(X_val)\n",
    "random_forest_val_pred = random_forest.predict(X_val)\n",
    "voting_val_pred = voting_clf.predict(X_val)\n",
    "\n",
    "# Evaluate models on validation data and print results\n",
    "for model_name, predictions in zip(\n",
    "    [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Voting Classifier\"],\n",
    "    [log_reg_val_pred, decision_tree_val_pred, random_forest_val_pred, voting_val_pred]\n",
    "):\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    print(f\"{model_name} Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_val, predictions))\n",
    "\n",
    "# Make predictions on the test set\n",
    "log_reg_test_pred = log_reg.predict(X_test)\n",
    "decision_tree_test_pred = decision_tree.predict(X_test)\n",
    "random_forest_test_pred = random_forest.predict(X_test)\n",
    "voting_test_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate models on test data and print results\n",
    "for model_name, predictions in zip(\n",
    "    [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Voting Classifier\"],\n",
    "    [log_reg_test_pred, decision_tree_test_pred, random_forest_test_pred, voting_test_pred]\n",
    "):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75552198-11de-463a-842b-27b07d594775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac407f6-4f0d-4224-a48c-c8eecbbd4659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65dd93-466d-4c38-bec5-12855cea88b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
