{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c9f0b7e-f1ee-440f-9c14-49df371d41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e02b22f-7515-4dc6-8f6b-77adaabb38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes_binary_classification_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00555c26-26c4-49fc-aa4a-575f39164785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Checks whats in the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9da9b80b-4b63-4866-87c2-3cb9eb48d2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(24206)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks duplicated in dataset\n",
    "# There is 24206 duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec4a7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data.drop('Diabetes_binary', axis=1)\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% train\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% validation, 15% test\n",
    "\n",
    "# Create preprocessing pipelines for numeric and categorical features\n",
    "numeric_features = ['BMI', 'MentHlth', 'PhysHlth', 'Age', 'Income']  # Non-binary variables\n",
    "categorical_features = ['GenHlth', 'Education', 'HighBP', 'HighChol', \n",
    "                        'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', \n",
    "                        'PhysActivity', 'Fruits', 'Veggies', \n",
    "                        'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', \n",
    "                        'DiffWalk', 'Sex']  # Binary variables\n",
    "\n",
    "# Create preprocessing for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess training data (numerical and categorical features)\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Preprocess validation and test data\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb74f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "log_reg = LogisticRegression(max_iter=2000)\n",
    "decision_tree = DecisionTreeClassifier(max_depth=50)\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=50)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg),\n",
    "    ('decision_tree', decision_tree),\n",
    "    ('random_forest', random_forest)],\n",
    "    voting='hard')  # 'hard' for majority voting\n",
    "\n",
    "# Fit models on the processed training data\n",
    "log_reg.fit(X_train_processed, y_train)\n",
    "decision_tree.fit(X_train_processed, y_train)\n",
    "random_forest.fit(X_train_processed, y_train)\n",
    "voting_clf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "log_reg_val_pred = log_reg.predict(X_val_processed)\n",
    "decision_tree_val_pred = decision_tree.predict(X_val_processed)\n",
    "random_forest_val_pred = random_forest.predict(X_val_processed)\n",
    "voting_val_pred = voting_clf.predict(X_val_processed)\n",
    "\n",
    "# Make predictions on the test set\n",
    "log_reg_test_pred = log_reg.predict(X_test_processed)\n",
    "decision_tree_test_pred = decision_tree.predict(X_test_processed)\n",
    "random_forest_test_pred = random_forest.predict(X_test_processed)\n",
    "voting_test_pred = voting_clf.predict(X_test_processed)\n",
    "\n",
    "# Make predictions on the test set\n",
    "log_reg_test_pred = log_reg.predict(X_test_processed)\n",
    "decision_tree_test_pred = decision_tree.predict(X_test_processed)\n",
    "random_forest_test_pred = random_forest.predict(X_test_processed)\n",
    "voting_test_pred = voting_clf.predict(X_test_processed)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg),\n",
    "    ('decision_tree', decision_tree),\n",
    "    ('random_forest', random_forest)],\n",
    "    voting='hard')  # 'hard' for majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c480fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate false negative rate\n",
    "def calculate_fnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0  # Avoid division by zero\n",
    "    return tn, fn, tp, fp, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68e71d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fnr(predictions, model_name):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    tn, fn, tp, fp, fnr = calculate_fnr(y_test, predictions)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"true Negatives: {tn}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negative Rate: {fnr:.4f}\")\n",
    "    print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95954645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 177576\n",
      "Validation set size: 38052\n",
      "Test set size: 38052\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19f1d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of models based on validation data:\n",
      "\n",
      "Logistic Regression\n",
      "Test Accuracy: 0.8343\n",
      "true Negatives: 31557\n",
      "False Negatives: 5003\n",
      "True Positives: 191\n",
      "False Positives: 1301\n",
      "False Negative Rate: 0.9632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.96      0.91     32858\n",
      "         1.0       0.13      0.04      0.06      5194\n",
      "\n",
      "    accuracy                           0.83     38052\n",
      "   macro avg       0.50      0.50      0.48     38052\n",
      "weighted avg       0.76      0.83      0.79     38052\n",
      "\n",
      "Decision Tree\n",
      "Test Accuracy: 0.7502\n",
      "true Negatives: 27765\n",
      "False Negatives: 4414\n",
      "True Positives: 780\n",
      "False Positives: 5093\n",
      "False Negative Rate: 0.8498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85     32858\n",
      "         1.0       0.13      0.15      0.14      5194\n",
      "\n",
      "    accuracy                           0.75     38052\n",
      "   macro avg       0.50      0.50      0.50     38052\n",
      "weighted avg       0.76      0.75      0.76     38052\n",
      "\n",
      "Random Forest\n",
      "Test Accuracy: 0.8239\n",
      "true Negatives: 31074\n",
      "False Negatives: 4916\n",
      "True Positives: 278\n",
      "False Positives: 1784\n",
      "False Negative Rate: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.95      0.90     32858\n",
      "         1.0       0.13      0.05      0.08      5194\n",
      "\n",
      "    accuracy                           0.82     38052\n",
      "   macro avg       0.50      0.50      0.49     38052\n",
      "weighted avg       0.76      0.82      0.79     38052\n",
      "\n",
      "Voting Classifier\n",
      "Test Accuracy: 0.8275\n",
      "true Negatives: 31242\n",
      "False Negatives: 4948\n",
      "True Positives: 246\n",
      "False Positives: 1616\n",
      "False Negative Rate: 0.9526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.95      0.90     32858\n",
      "         1.0       0.13      0.05      0.07      5194\n",
      "\n",
      "    accuracy                           0.83     38052\n",
      "   macro avg       0.50      0.50      0.49     38052\n",
      "weighted avg       0.76      0.83      0.79     38052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on validation data and print results\n",
    "print(f\"Evaluation of models based on validation data:\")\n",
    "print(f\"\")\n",
    "for model_name, predictions in zip(\n",
    "    [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Voting Classifier\"],\n",
    "    [log_reg_val_pred, decision_tree_val_pred, random_forest_val_pred, voting_val_pred]\n",
    "):\n",
    "    print_fnr(predictions, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8dbd1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Test Accuracy: 0.8686\n",
      "true Negatives: 32248\n",
      "False Negatives: 4390\n",
      "True Positives: 804\n",
      "False Positives: 610\n",
      "False Negative Rate: 0.8452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     32858\n",
      "         1.0       0.57      0.15      0.24      5194\n",
      "\n",
      "    accuracy                           0.87     38052\n",
      "   macro avg       0.72      0.57      0.59     38052\n",
      "weighted avg       0.84      0.87      0.83     38052\n",
      "\n",
      "Decision Tree\n",
      "Test Accuracy: 0.8007\n",
      "true Negatives: 28747\n",
      "False Negatives: 3474\n",
      "True Positives: 1720\n",
      "False Positives: 4111\n",
      "False Negative Rate: 0.6688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88     32858\n",
      "         1.0       0.29      0.33      0.31      5194\n",
      "\n",
      "    accuracy                           0.80     38052\n",
      "   macro avg       0.59      0.60      0.60     38052\n",
      "weighted avg       0.81      0.80      0.81     38052\n",
      "\n",
      "Random Forest\n",
      "Test Accuracy: 0.8598\n",
      "true Negatives: 31767\n",
      "False Negatives: 4244\n",
      "True Positives: 950\n",
      "False Positives: 1091\n",
      "False Negative Rate: 0.8171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92     32858\n",
      "         1.0       0.47      0.18      0.26      5194\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.67      0.57      0.59     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n",
      "Voting Classifier\n",
      "Test Accuracy: 0.8618\n",
      "true Negatives: 31913\n",
      "False Negatives: 4312\n",
      "True Positives: 882\n",
      "False Positives: 945\n",
      "False Negative Rate: 0.8302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92     32858\n",
      "         1.0       0.48      0.17      0.25      5194\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.68      0.57      0.59     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on test data and print results\n",
    "for model_name, predictions in zip(\n",
    "    [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Voting Classifier\"],\n",
    "    [log_reg_test_pred, decision_tree_test_pred, random_forest_test_pred, voting_test_pred]\n",
    "):\n",
    "    print_fnr(predictions, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55b520c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top correlations with Diabetes_binary:\n",
      "Diabetes_binary             1.000000\n",
      "HighBP_1.0                  0.263531\n",
      "DiffWalk_1.0                0.221507\n",
      "BMI                         0.218647\n",
      "HighChol_1.0                0.197866\n",
      "GenHlth_4.0                 0.186045\n",
      "HeartDiseaseorAttack_1.0    0.179718\n",
      "Age                         0.176577\n",
      "PhysHlth                    0.171694\n",
      "GenHlth_5.0                 0.156761\n",
      "PhysActivity_0.0            0.118985\n",
      "Stroke_1.0                  0.107874\n",
      "GenHlth_3.0                 0.071468\n",
      "MentHlth                    0.070958\n",
      "CholCheck_1.0               0.065421\n",
      "Education_4.0               0.062446\n",
      "Smoker_1.0                  0.062066\n",
      "Education_3.0               0.058617\n",
      "Education_2.0               0.058124\n",
      "Veggies_0.0                 0.057552\n",
      "HvyAlcoholConsump_0.0       0.057065\n",
      "Fruits_0.0                  0.039896\n",
      "NoDocbcCost_1.0             0.033110\n",
      "Sex_1.0                     0.032150\n",
      "Education_5.0               0.014771\n",
      "AnyHealthcare_1.0           0.014540\n",
      "Education_1.0               0.010815\n",
      "AnyHealthcare_0.0          -0.014540\n",
      "Sex_0.0                    -0.032150\n",
      "NoDocbcCost_0.0            -0.033110\n",
      "Fruits_1.0                 -0.039896\n",
      "HvyAlcoholConsump_1.0      -0.057065\n",
      "Veggies_1.0                -0.057552\n",
      "Smoker_0.0                 -0.062066\n",
      "CholCheck_0.0              -0.065421\n",
      "Education_6.0              -0.105820\n",
      "Stroke_0.0                 -0.107874\n",
      "PhysActivity_1.0           -0.118985\n",
      "GenHlth_2.0                -0.143656\n",
      "GenHlth_1.0                -0.154189\n",
      "Income                     -0.164444\n",
      "HeartDiseaseorAttack_0.0   -0.179718\n",
      "HighChol_0.0               -0.197866\n",
      "DiffWalk_0.0               -0.221507\n",
      "HighBP_0.0                 -0.263531\n",
      "Name: Diabetes_binary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Perform correlation analysis\n",
    "correlation_matrix = X_train_processed_df.corr()\n",
    "sorted_correlations = correlation_matrix['Diabetes_binary'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Top correlations with Diabetes_binary:\")\n",
    "print(sorted_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11fe236a-9a13-4d0b-88d8-6d4ff1dda136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy: 0.8637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     32747\n",
      "         1.0       0.54      0.15      0.24      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.71      0.57      0.58     38052\n",
      "weighted avg       0.83      0.86      0.83     38052\n",
      "\n",
      "Decision Tree Validation Accuracy: 0.7961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88     32747\n",
      "         1.0       0.29      0.33      0.31      5305\n",
      "\n",
      "    accuracy                           0.80     38052\n",
      "   macro avg       0.59      0.60      0.59     38052\n",
      "weighted avg       0.81      0.80      0.80     38052\n",
      "\n",
      "Random Forest Validation Accuracy: 0.8551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92     32747\n",
      "         1.0       0.45      0.17      0.25      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.66      0.57      0.58     38052\n",
      "weighted avg       0.82      0.86      0.83     38052\n",
      "\n",
      "Voting Classifier Validation Accuracy: 0.8590\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92     32747\n",
      "         1.0       0.48      0.17      0.25      5305\n",
      "\n",
      "    accuracy                           0.86     38052\n",
      "   macro avg       0.68      0.57      0.59     38052\n",
      "weighted avg       0.82      0.86      0.83     38052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on validation data and print results\n",
    "for model_name, predictions in zip(\n",
    "    [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Voting Classifier\"],\n",
    "    [log_reg_val_pred, decision_tree_val_pred, random_forest_val_pred, voting_val_pred]\n",
    "):\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    print(f\"{model_name} Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_val, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
